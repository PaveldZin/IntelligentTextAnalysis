{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импрорт датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = pd.read_csv('data/positive.csv', sep=',', usecols=[3], names=['text'], skiprows=1)\n",
    "df_positive['label'] = 'positive'\n",
    "df_negative = pd.read_csv('data/negative.csv', sep=',', usecols=[3], names=['text'], skiprows=1)\n",
    "df_negative['label'] = 'negative'\n",
    "df = pd.concat([df_positive, df_negative], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182518</th>\n",
       "      <td>Все покупают подарки, а я дома с температурой!...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101872</th>\n",
       "      <td>Мне много не надо... Власть над миром и чего-н...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222805</th>\n",
       "      <td>@annett_14 @Vukadinovich дааа уж...просто слов...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190257</th>\n",
       "      <td>расстроеная и заплаканая иду спать :( всем сла...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34813</th>\n",
       "      <td>@akhitruk :)) просто переживаю, чтобы они себе...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61388</th>\n",
       "      <td>Сидим на работе в темноте все утро, отдыхаем))...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187397</th>\n",
       "      <td>RT @sd0107: «Наша страна стала лучше, богаче, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58970</th>\n",
       "      <td>Сегодня \"напросился\" к одногрупнику на поесть,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188131</th>\n",
       "      <td>@Nastya_Ertulova ВЕЗЁТ ТЕБЕ, А Я В ЧЕТЫРЕ УТРА...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98009</th>\n",
       "      <td>@Hey_hey_bitch этой традиции уже несколько век...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "182518  Все покупают подарки, а я дома с температурой!...  negative\n",
       "101872  Мне много не надо... Власть над миром и чего-н...  positive\n",
       "222805  @annett_14 @Vukadinovich дааа уж...просто слов...  negative\n",
       "190257  расстроеная и заплаканая иду спать :( всем сла...  negative\n",
       "34813   @akhitruk :)) просто переживаю, чтобы они себе...  positive\n",
       "61388   Сидим на работе в темноте все утро, отдыхаем))...  positive\n",
       "187397  RT @sd0107: «Наша страна стала лучше, богаче, ...  negative\n",
       "58970   Сегодня \"напросился\" к одногрупнику на поесть,...  positive\n",
       "188131  @Nastya_Ertulova ВЕЗЁТ ТЕБЕ, А Я В ЧЕТЫРЕ УТРА...  negative\n",
       "98009   @Hey_hey_bitch этой традиции уже несколько век...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "positive    114911\n",
       "negative    111923\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чистка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'@\\w+', '', text) #remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text) #remove hashtags\n",
    "    text = re.sub(r'http\\S+', '', text) #remove urls\n",
    "    text = re.sub('[{}]'.format(punctuation), ' ', text) #remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text) #remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text) #remove extra whitespaces\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pavel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "to_remove = stopwords.words('russian') + ['RT', '', ' ', '\\n']\n",
    "#to_remove = ['RT', '', ' ', '\\n']\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    mystem_analyzer = Mystem(grammar_info=False)\n",
    "    lemmas = mystem_analyzer.lemmatize(text)\n",
    "    lemmas[-1] = lemmas[-1].rstrip()\n",
    "    return [word for word in lemmas if word not in to_remove]\n",
    "\n",
    "def preprocess(text):\n",
    "    text = clean_text(text)\n",
    "    text = lemmatize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_batch(text):\n",
    "    merged_text = \" sep \".join(text)\n",
    "\n",
    "    doc = []\n",
    "    res = []\n",
    "\n",
    "    for t in preprocess(merged_text):\n",
    "        if t.strip() != 'sep':\n",
    "            doc.append(t)\n",
    "        else:\n",
    "            res.append(doc)\n",
    "            doc = []\n",
    "    res.append(doc)\n",
    "    return res\n",
    "\n",
    "def parallel_preprocess(data, batch_size=1000):\n",
    "    texts = data.values\n",
    "\n",
    "    text_batch = [texts[i: i + batch_size] for i in range(0, len(texts), batch_size)]\n",
    "    processed_texts = Parallel(n_jobs=-1, backend=\"threading\")(delayed(process_batch)(t) for t in tqdm(text_batch))\n",
    "    combined_texts = [' '.join(text) for batch in processed_texts for text in batch]\n",
    "    return pd.Series(combined_texts, index=data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = parallel_preprocess(x_train)\n",
    "x_test = parallel_preprocess(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107097             немного выпивать говорить ничто говорить\n",
       "224163     твой общение шутка соскучиться че давно видеться\n",
       "63992                              ахахаахх собака называть\n",
       "108549    лично вообще барабан гиа написать заморачивать...\n",
       "67962            наташа реальный китаец писать хер понимать\n",
       "                                ...                        \n",
       "119879    хотеть графический планшетик скоро приходить х...\n",
       "103694                                           работяга D\n",
       "131932           дом год приходиться второй раковина менять\n",
       "146867                                 представлять бояться\n",
       "121958           день месяц общаться мм время быстро лететь\n",
       "Length: 181467, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec_unigram = TfidfVectorizer(ngram_range=(1, 1))\n",
    "vec_bigram = TfidfVectorizer(ngram_range=(2, 2))\n",
    "vec_multigram = TfidfVectorizer(ngram_range=(1, 3))\n",
    "#select vectorizer\n",
    "vec = vec_unigram\n",
    "vec_train = vec.fit_transform(x_train)\n",
    "vec_test = vec.transform(x_test)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(vec, 'vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.71      0.71     22131\n",
      "    positive       0.72      0.71      0.71     23236\n",
      "\n",
      "    accuracy                           0.71     45367\n",
      "   macro avg       0.71      0.71      0.71     45367\n",
      "weighted avg       0.71      0.71      0.71     45367\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RandomForest.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, min_samples_leaf=3, n_jobs=-1)\n",
    "clf.fit(vec_train, y_train)\n",
    "pred = clf.predict(vec_test)\n",
    "print('classification report for Random Forest:')\n",
    "print(classification_report(pred, y_test))\n",
    "joblib.dump(clf, 'RandomForest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.72      0.71     22223\n",
      "    positive       0.72      0.72      0.72     23144\n",
      "\n",
      "    accuracy                           0.72     45367\n",
      "   macro avg       0.72      0.72      0.72     45367\n",
      "weighted avg       0.72      0.72      0.72     45367\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SVM.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(dual=True)\n",
    "clf.fit(vec_train, y_train)\n",
    "pred = clf.predict(vec_test)\n",
    "print('classification report for SVM:')\n",
    "print(classification_report(pred, y_test))\n",
    "joblib.dump(clf, 'SVM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report for Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.72      0.71     22242\n",
      "    positive       0.73      0.72      0.72     23125\n",
      "\n",
      "    accuracy                           0.72     45367\n",
      "   macro avg       0.72      0.72      0.72     45367\n",
      "weighted avg       0.72      0.72      0.72     45367\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NaiveBayes.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(vec_train, y_train)\n",
    "pred = clf.predict(vec_test)\n",
    "print('classification report for Naive Bayes:')\n",
    "print(classification_report(pred, y_test))\n",
    "joblib.dump(clf, 'NaiveBayes.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ансамбль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report for Ensemble:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.73      0.72     22046\n",
      "    positive       0.74      0.72      0.73     23321\n",
      "\n",
      "    accuracy                           0.72     45367\n",
      "   macro avg       0.72      0.72      0.72     45367\n",
      "weighted avg       0.72      0.72      0.72     45367\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ensemble.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators=100, min_samples_leaf=3, n_jobs=-1)\n",
    "clf2 = LinearSVC()\n",
    "clf3 = MultinomialNB()\n",
    "\n",
    "voting_ensemble = VotingClassifier(estimators=[('rf', clf1), ('svm', clf2), ('nb', clf3)], voting='hard', n_jobs=-1)\n",
    "voting_ensemble.fit(vec_train, y_train)\n",
    "pred = voting_ensemble.predict(vec_test)\n",
    "print('classification report for Ensemble:')\n",
    "print(classification_report(pred, y_test))\n",
    "joblib.dump(voting_ensemble, 'Ensemble.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
